# -*- coding: utf-8 -*-
"""
Level 3ï¼šNSGA-II å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆæŒ‰ tpms_type åˆ†ç»„ï¼‰
-------------------------------------------------------
è®¾è®¡æ€è·¯ï¼š
  - å¯¹æ¯ä¸€ç§ TPMS ç»“æ„ (G / KEL / VOR ç­‰) åˆ†åˆ«æ„å»ºä»£ç†æ¨¡å‹ã€
          åˆ†åˆ«åœ¨è¯¥ç»“æ„æ—çš„æ•°æ®èŒƒå›´å†…åš NSGA-II ä¼˜åŒ–ï¼Œ
          æœ€åæŠŠæ‰€æœ‰ç»“æ„çš„ Pareto è§£åˆå¹¶åˆ°ä¸€ä¸ªæ–‡ä»¶å’Œä¸€å¼ å›¾ä¸­ã€‚

ğŸ¯ ç›®æ ‡ï¼š
  - æœ€å°åŒ–ï¼šdp_per_L_pred   ï¼ˆå•ä½å‹é™ï¼‰
  - æœ€å¤§åŒ–ï¼šperm_pred       ï¼ˆæ¸—é€ç‡ï¼Œåœ¨ç®—æ³•ä¸­ç”¨ -perm è¡¨ç¤ºï¼‰

ğŸ”§ è®¾è®¡å˜é‡ï¼ˆè¿ç»­å˜é‡ï¼‰ï¼š
  - u_in
  - t_wall
  - cell_size


ğŸ“‚ è¾“å…¥æ•°æ®ï¼š
  - data/dataset_surrogate.csv

ğŸ“¤ è¾“å‡ºç»“æœï¼š
  - out/pareto_level3_all_types.csv   : åˆå¹¶åçš„å¸•ç´¯æ‰˜è§£ï¼ˆå« tpms_typeï¼‰
  - out/pareto_level3_all_types.png   : ä¸åŒç»“æ„ç±»åˆ«çš„ Pareto å‰æ²¿å¯¹æ¯”å›¾
  - out/nsga2_level3_config.json      : ä¼˜åŒ–é…ç½®å¿«ç…§
  - out/rf_metrics_level3.json        : å„ç»“æ„ä»£ç†æ¨¡å‹ç²¾åº¦æŒ‡æ ‡
"""

import os
from pathlib import Path
import json
import random
from typing import List, Tuple, Dict

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

from pymoo.core.problem import ElementwiseProblem
from pymoo.algorithms.moo.nsga2 import NSGA2
from pymoo.termination import get_termination
from pymoo.optimize import minimize
from pymoo.operators.sampling.lhs import LHS
from pymoo.operators.crossover.sbx import SBX
from pymoo.operators.mutation.pm import PM

import sklearn
import matplotlib.pyplot as plt


# =====================================================
# 0. å…¨å±€éšæœºç§å­è®¾ç½®ï¼ˆä¿è¯å¯å¤ç°æ€§ï¼‰
# =====================================================
SEED = 42
os.environ["PYTHONHASHSEED"] = str(SEED)


def set_global_seed(seed: int = SEED):
    random.seed(seed)
    np.random.seed(seed)


# =====================================================
# 1. è·¯å¾„ä¸åŸºç¡€é…ç½®
# =====================================================
ROOT = Path(__file__).resolve().parents[1]
DATASET_CSV = ROOT / "data" / "dataset_surrogate.csv"   # æˆ– ç»å¯¹è·¯å¾„
OUT_DIR = ROOT / "out"

# è®¾è®¡å˜é‡å€™é€‰
X_VARS_BASE = ["u_in", "t_wall", "eps", "cell_size"]
INCLUDE_DH_IN_X = True
INCLUDE_UVOL_IN_X = True

# ç›®æ ‡åˆ—
OBJ_MIN = "dp_per_L"
OBJ_MAX = "perm"

# RF & NSGA-II å‚æ•°
TEST_SIZE = 0.2
RF_PARAMS = dict(
    n_estimators=500,
    max_depth=22,
    random_state=SEED,
    n_jobs=1,    # å•çº¿ç¨‹ä¿è¯å¯å¤ç°
)
POP = 80
GEN = 40
BOUNDS_MODE = ("quantile", 0.01, 0.99)  # ä½¿ç”¨ 1% ~ 99% åˆ†ä½æ•°ä½œä¸ºè¾¹ç•Œ


# =====================================================
# 2. å·¥å…·å‡½æ•°ï¼šæ•°æ®ä¸ç‰¹å¾
# =====================================================
def load_df(path: Path) -> pd.DataFrame:
    if not path.is_file():
        raise FileNotFoundError(path)
    df = pd.read_csv(path)
    df.columns = [str(c).strip() for c in df.columns]

    for c in df.columns:
        if df[c].dtype.kind not in "biufc" and c not in ["run_id", "tpms_type"]:
            df[c] = pd.to_numeric(df[c], errors="ignore")
    return df


def choose_design_cols(df: pd.DataFrame) -> List[str]:
    """
    ç»™å®šä¸€ä¸ªå­æ•°æ®é›†ï¼ˆå•ä¸€ tpms_typeï¼‰ï¼Œè‡ªåŠ¨å†³å®šè¿ç»­è®¾è®¡å˜é‡åˆ—ã€‚
    æ³¨æ„ï¼šè¿™é‡Œæ•…æ„ä¸æŠŠ tpms_type æ”¾åˆ° X é‡Œï¼Œå› ä¸ºå·²ç»æŒ‰ç±»å‹åˆ†ç»„ã€‚
    """
    x_vars = list(X_VARS_BASE)
    if INCLUDE_DH_IN_X and "Dh" in df.columns:
        x_vars.append("Dh")
    if INCLUDE_UVOL_IN_X and "u_vol" in df.columns:
        x_vars.append("u_vol")

    num_cols = [c for c in x_vars if c in df.columns]
    return num_cols


def build_preproc(num_cols: List[str]) -> ColumnTransformer:
    """
    å¯¹äºå•ä¸€ç»“æ„ç±»å‹çš„æ•°æ®ï¼Œtpms_type æ²¡æœ‰åŒºåˆ†åº¦ï¼Œå› æ­¤ä¸ä½œä¸ºè¾“å…¥ç‰¹å¾ï¼›
    åªå¯¹è¿ç»­ç‰¹å¾åš passthroughã€‚
    """
    return ColumnTransformer([("num", "passthrough", num_cols)], remainder="drop")


# =====================================================
# 3. ä»£ç†æ¨¡å‹è®­ç»ƒï¼ˆå¯¹æ¯ä¸ª tpms_type ç‹¬ç«‹è®­ç»ƒï¼‰
# =====================================================
def train_model_for_type(
    df_type: pd.DataFrame,
    num_cols: List[str],
    ycol: str,
    seed: int,
) -> Tuple[Pipeline, Dict]:
    """
    å¯¹æŸä¸€ä¸ª tpms_type çš„æ•°æ®å­é›†ï¼Œè®­ç»ƒå•ç›®æ ‡ RF å›å½’æ¨¡å‹ã€‚
    """
    if ycol not in df_type.columns:
        raise ValueError(f"æ•°æ®é›†ä¸­ç¼ºå°‘ç›®æ ‡åˆ—ï¼š{ycol}")

    X = df_type[num_cols].copy()
    y = pd.to_numeric(df_type[ycol], errors="coerce").values

    mask = ~X.isna().any(axis=1) & np.isfinite(y)
    Xuse, yuse = X.loc[mask], y[mask]
    if len(yuse) < 30:
        raise ValueError(f"[{ycol}] ç±»å‹ {df_type['tpms_type'].iloc[0]} å¯ç”¨æ ·æœ¬è¿‡å°‘ï¼š{len(yuse)}")

    Xtr, Xte, ytr, yte = train_test_split(
        Xuse,
        yuse,
        test_size=TEST_SIZE,
        random_state=seed,
    )

    prep = build_preproc(num_cols)
    rf = RandomForestRegressor(**{**RF_PARAMS, "random_state": seed})
    pipe = Pipeline([("prep", prep), ("rf", rf)])
    pipe.fit(Xtr, ytr)

    pred = pipe.predict(Xte)
    metrics = dict(
        r2=float(r2_score(yte, pred)),
        mae=float(mean_absolute_error(yte, pred)),
        rmse=float(np.sqrt(mean_squared_error(yte, pred))),
        n_test=int(len(yte)),
    )
    return pipe, metrics


def bounds_from_data(df_type: pd.DataFrame, num_cols: List[str]) -> Dict[str, Tuple[float, float]]:
    """
    åœ¨å•ä¸€ tpms_type å­é›†ä¸Šï¼Œç”¨åˆ†ä½æ•°ç»™å‡ºè¿ç»­è®¾è®¡å˜é‡çš„è¾¹ç•Œï¼Œ
    é¿å…æŠŠå…¶å®ƒç»“æ„çš„æç«¯ eps / cell_size å¼•å…¥è¿™ä¸ªç»“æ„æ—çš„æœç´¢ç©ºé—´ã€‚
    """
    bounds = {}
    for c in num_cols:
        s = pd.to_numeric(df_type[c], errors="coerce").dropna()
        if not len(s):
            bounds[c] = (0.0, 1.0)
            continue

        if BOUNDS_MODE[0] == "quantile":
            lo, hi = s.quantile(BOUNDS_MODE[1]), s.quantile(BOUNDS_MODE[2])
        else:
            lo, hi = s.min(), s.max()

        if not np.isfinite(lo) or not np.isfinite(hi) or hi <= lo:
            lo, hi = s.min(), s.max()
        bounds[c] = (float(lo), float(hi))
    return bounds


# =====================================================
# 4. NSGA-II é—®é¢˜ï¼ˆElementwiseProblemï¼‰
# =====================================================
class PerTypeProblem(ElementwiseProblem):
    """
    å¯¹â€œæŸä¸€ç§ tpms_typeâ€çš„ç»“æ„ï¼Œåœ¨å…¶æ•°æ®å¯¹åº”çš„è¿ç»­è®¾è®¡ç©ºé—´ä¸ŠåšåŒç›®æ ‡ä¼˜åŒ–ï¼š

      F[0] = dp_per_L_pred
      F[1] = -perm_pred
    """

    def __init__(
        self,
        num_cols: List[str],
        var_bounds: Dict[str, Tuple[float, float]],
        model_dp: Pipeline,
        model_perm: Pipeline,
    ):
        self.num_cols = num_cols
        self.var_bounds = var_bounds   # âš ï¸ æ³¨æ„è¿™é‡Œé¿å…ç”¨ self.bounds è¦†ç›–åŸºç±»æ–¹æ³•
        self.model_dp = model_dp
        self.model_perm = model_perm

        xl = np.array([self.var_bounds[v][0] for v in num_cols], dtype=float)
        xu = np.array([self.var_bounds[v][1] for v in num_cols], dtype=float)

        super().__init__(n_var=len(num_cols), n_obj=2, n_constr=0, xl=xl, xu=xu)

    def _evaluate(self, x, out, *args, **kwargs):
        row = {v: float(x[i]) for i, v in enumerate(self.num_cols)}
        Xdf = pd.DataFrame([row])

        dp = float(self.model_dp.predict(Xdf[self.num_cols])[0])
        pr = float(self.model_perm.predict(Xdf[self.num_cols])[0])

        out["F"] = np.array([dp, -pr], dtype=float)


# =====================================================
# 5. å¯¹å•ä¸€ tpms_type è¿è¡Œ NSGA-II å¹¶è¿”å› Pareto è§£
# =====================================================
def optimize_one_type(
    df_type: pd.DataFrame,
    tpms_type_value: str,
    seed: int = SEED,
) -> Tuple[pd.DataFrame, Dict[str, Dict]]:
    """
    å¯¹å•ä¸€ tpms_typeï¼ˆä¾‹å¦‚ 'G' æˆ– 'KEL'ï¼‰ï¼š
      1. é€‰æ‹©è®¾è®¡å˜é‡åˆ—
      2. è®­ç»ƒ dp_per_L / perm çš„ RF ä»£ç†
      3. è®¡ç®—è¿ç»­å˜é‡è¾¹ç•Œ
      4. è·‘ NSGA-IIï¼Œè¿”å›å¸•ç´¯æ‰˜è§£ DataFrame å’Œæ¨¡å‹æŒ‡æ ‡
    """
    set_global_seed(seed)

    num_cols = choose_design_cols(df_type)

    # è®­ç»ƒä¸¤ä¸ªä»£ç†æ¨¡å‹
    model_dp, m_dp = train_model_for_type(df_type, num_cols, OBJ_MIN, seed + 1)
    model_perm, m_perm = train_model_for_type(df_type, num_cols, OBJ_MAX, seed + 2)

    metrics = {OBJ_MIN: m_dp, OBJ_MAX: m_perm}

    # è¾¹ç•Œï¼ˆä»…åŸºäºå½“å‰ç»“æ„çš„æ ·æœ¬ï¼‰
    bounds = bounds_from_data(df_type, num_cols)

    # é…ç½® NSGA-II é—®é¢˜ä¸ç®—æ³•
    problem = PerTypeProblem(
        num_cols=num_cols,
        var_bounds=bounds,      # âœ… è¿™é‡Œä¼ çš„æ˜¯ var_bounds
        model_dp=model_dp,
        model_perm=model_perm,
    )

    mut_prob = 1.0 / max(1, len(num_cols))
    algo = NSGA2(
        pop_size=POP,
        sampling=LHS(),
        crossover=SBX(prob=0.9, eta=15),
        mutation=PM(prob=mut_prob, eta=20),
    )
    termination = get_termination("n_gen", GEN)

    set_global_seed(seed)
    res = minimize(
        problem,
        algo,
        termination,
        seed=seed,
        verbose=True,
    )

    X = getattr(res, "X", None)
    if X is None or len(X) == 0:
        return pd.DataFrame(), metrics

    pareto = pd.DataFrame(X, columns=num_cols)
    pareto[OBJ_MIN + "_pred"] = model_dp.predict(pareto[num_cols])
    pareto[OBJ_MAX + "_pred"] = model_perm.predict(pareto[num_cols])

    pareto = pareto.sort_values(
        by=[OBJ_MIN + "_pred", OBJ_MAX + "_pred"],
        ascending=[True, False],
    ).reset_index(drop=True)

    # è¡¥ä¸Šç»“æ„ç±»å‹
    pareto["tpms_type"] = tpms_type_value

    return pareto, metrics


# =====================================================
# 6. ä¸»æµç¨‹ï¼šå¯¹æ‰€æœ‰ tpms_type ä¾æ¬¡ä¼˜åŒ–å¹¶æ±‡æ€»
# =====================================================
def main():
    set_global_seed(SEED)
    OUT_DIR.mkdir(parents=True, exist_ok=True)

    df = load_df(DATASET_CSV)

    if "tpms_type" not in df.columns:
        raise ValueError("æ•°æ®é›†ä¸­ç¼ºå°‘ tpms_type åˆ—ï¼Œè¯·æ£€æŸ¥ï¼")

    all_types = sorted(df["tpms_type"].dropna().unique().tolist())
    if len(all_types) == 0:
        raise ValueError("tpms_type åˆ—ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ï¼")

    print(f"æ£€æµ‹åˆ°çš„ TPMS ç±»å‹ï¼š{all_types}")

    all_pareto = []
    all_metrics = {}

    for i, tp in enumerate(all_types):
        print("=" * 60)
        print(f"[Level 3] æ­£åœ¨ä¼˜åŒ–ç»“æ„ç±»å‹ tpms_type = {tp}")
        df_type = df[df["tpms_type"] == tp].copy()

        pareto_tp, metrics_tp = optimize_one_type(
            df_type=df_type,
            tpms_type_value=tp,
            seed=SEED + i * 100,
        )

        if not pareto_tp.empty:
            all_pareto.append(pareto_tp)
            all_metrics[tp] = metrics_tp
            print(f"  -> {tp} ç±»å‹å¾—åˆ° {len(pareto_tp)} ä¸ªå¸•ç´¯æ‰˜è§£ã€‚")
        else:
            print(f"  -> {tp} ç±»å‹æ²¡æœ‰å¾—åˆ°æœ‰æ•ˆè§£ï¼Œè·³è¿‡ã€‚")

    if not all_pareto:
        print("âš  æ‰€æœ‰ç±»å‹éƒ½æœªè·å¾—å¸•ç´¯æ‰˜è§£ï¼Œç»ˆæ­¢ã€‚")
        return

    pareto_all = pd.concat(all_pareto, ignore_index=True)

    out_csv = OUT_DIR / "pareto_level3_all_types.csv"
    pareto_all.to_csv(
        out_csv,
        index=False,
        encoding="utf-8-sig",
        float_format="%.10g",
    )
    print(f"âœ… åˆå¹¶åçš„å¸•ç´¯æ‰˜è§£å·²ä¿å­˜ï¼š{out_csv} (rows = {len(pareto_all)})")

    # ä¿å­˜ RF ç²¾åº¦æŒ‡æ ‡ï¼ˆæŒ‰ç±»å‹ï¼‰
    (OUT_DIR / "rf_metrics_level3.json").write_text(
        json.dumps(all_metrics, indent=2, ensure_ascii=False),
        encoding="utf-8",
    )
    print("âœ… å„ç»“æ„ç±»å‹çš„ RF æ¨¡å‹æŒ‡æ ‡å·²ä¿å­˜ï¼šout/rf_metrics_level3.json")

    # ç”» Pareto å‰æ²¿ï¼šä¸åŒ tpms_type ç”¨ä¸åŒé¢œè‰²
    plt.rcParams["font.family"] = "Times New Roman"
    plt.figure(figsize=(6, 4))

    for tp in all_types:
        sub = pareto_all[pareto_all["tpms_type"] == tp]
        if sub.empty:
            continue
        plt.scatter(
            sub[OBJ_MIN + "_pred"],
            sub[OBJ_MAX + "_pred"],
            s=20,
            alpha=0.7,
            label=f"{tp}",
        )

    plt.xlabel(f"{OBJ_MIN}_pred", fontsize=11)
    plt.ylabel(f"{OBJ_MAX}_pred", fontsize=11)
    plt.title("Pareto Fronts by TPMS Type (Level 3)", fontsize=12)
    plt.grid(alpha=0.3)
    plt.legend(title="tpms_type", fontsize=9)
    plt.tight_layout()

    out_fig = OUT_DIR / "pareto_level3_all_types.png"
    plt.savefig(out_fig, dpi=300)
    plt.close()
    print(f"âœ… å¤šç»“æ„ç±»å‹çš„ Pareto å¯¹æ¯”å›¾å·²ä¿å­˜ï¼š{out_fig}")

    # ä¿å­˜é…ç½®å¿«ç…§
    snapshot = {
        "DATASET_CSV": str(DATASET_CSV),
        "tpms_types": all_types,
        "POP": POP,
        "GEN": GEN,
        "SEED": SEED,
        "BOUNDS_MODE": BOUNDS_MODE,
        "X_VARS_BASE": X_VARS_BASE,
        "INCLUDE_DH_IN_X": INCLUDE_DH_IN_X,
        "INCLUDE_UVOL_IN_X": INCLUDE_UVOL_IN_X,
        "NOTE": "Level 3 per-type NSGA-II; each tpms_type optimized in its own design space.",
    }
    (OUT_DIR / "nsga2_level3_config.json").write_text(
        json.dumps(snapshot, indent=2, ensure_ascii=False),
        encoding="utf-8",
    )
    print("âœ… é…ç½®å¿«ç…§å·²ä¿å­˜ï¼šout/nsga2_level3_config.json")


if __name__ == "__main__":
    main()
